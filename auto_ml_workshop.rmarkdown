---
title: "auto_ml_workshop"
---


# Automated Machine Learning with R and h2o - Practice

Workshop 3 (HS120) \@ Swiss Days of Official Statistics, 30.08.2023, Universität Basel

## Load libraries

We need the following two libraries:


```{r}
library(tidyverse)
library(h2o)
```


## Get the data

We will use an OGD dataset for this workshop, available at [data.bl.ch](https://data.bl.ch/explore/dataset/12160/table). The data contains all the publicly available information of buildings in the Canton of Basel-Landschaft (cantonal register of buildings and dwellings).

For this example, the dataset is already preprocessed and filtered to **existing residential buildings** (the preprocessing script is available [here](https://github.com/lucahuesler/automl_workshop/blob/master/preprocessing.qmd)). We first load the data and check the dimensions:


```{r}
kgwr_residential <- read_rds("data/kgwr_residential.rds")

dim(kgwr_residential)
```


Our dataset contains 61'139 buildings with 62 variables.

## The challenge

For about 1'600 (2.6%) residential buildings in the Canton Basel-Landschaft, the energy source is unknown. You can find the information about the energy in the variable `energie_waermequelle_heizung_primaer_gruppiert`. Let's have a look at the variable: 


```{r}
kgwr_residential %>%
  count(energie_waermequelle_heizung_primaer_gruppiert) %>%
  mutate(energie_waermequelle_heizung_primaer_gruppiert = 
           reorder(energie_waermequelle_heizung_primaer_gruppiert, -n)) %>%
  ggplot(aes(x = energie_waermequelle_heizung_primaer_gruppiert, y = n, 
             fill = (energie_waermequelle_heizung_primaer_gruppiert == "Undefined"))) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("TRUE" = "red", "FALSE" = "grey50")) +
  labs(title = "Distribution of energy source of primary heating system", 
       x = "Energy source of primary Heating System", 
       y = "Number of Buildings") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")

```


In this exercise, we will try to find out if we can find a good classification model with AutoML that could help us determine the energy source of the buildings where no information is available.

Before we start, let's get a quick overview of these buildings:


```{r}

# dataframe with buildings that have undefined energy source
buildings_undefined_energy <- kgwr_residential %>%
  filter(energie_waermequelle_heizung_primaer_gruppiert == "Undefined")


buildings_undefined_energy %>%
  ggplot(aes(x = baujahr_des_gebaeudes)) +
  geom_bar() +
  labs(title = "Distribution by Year of Construction", 
       x = "Year of Construction", 
       y = "Number of Buildings") +
  theme_minimal()

```


We can see that most of the concerned buildings are rather new buildings, especially a high fraction of them was built between 2000-2010.


```{r}
buildings_undefined_energy %>%
  ggplot(aes(x = gebaeudeklasse_bezeichnung)) +
  geom_bar() +
  labs(title = "Distribution by Building Class", 
       x = "Building Class", 
       y = "Number of Buildings") +
  theme_minimal()
```


Around 1'200 (ca. 75%) of these buildings are single-family houses.

## Prepare data

Our goal is to predict the energy source of buildings with missing information (= `Undefined`). For modelling, create a new data frame `kgwr_residential_modelling`, where these buildings are removed.


```{r}
kgwr_residential_modelling <- kgwr_residential |>
  filter(energie_waermequelle_heizung_primaer_gruppiert != "Undefined")
```


In this exercise, we will use a very simple approach for variable selection and just use a few variables that could potentially contain some information about the heating system:

-   `gemeindename`: As the energy mix varies among municipalities (e.g. gas distribution only in some municipalities)
-   `e_gebaeudekoordinate` and `n_gebaeudekoordinate`: The coordinates of a building might also tell us something about the energy source (e.g. presence of district heating)
-   `baujahr_des_gebaeudes`: We also consider the construction year as the choice of the heating system evolved over time (see e.g. [Wohngebäude nach Energieträger der Heizung und Bauperiode 2020](https://www.statistik.bl.ch/web_portal/8_2_4?year=prozentual)).
-   `gebaeudeflaeche` and `anzahl_geschosse`: The building area and number of floors finally provide information about dimensions of a building which can also influence the choice of the heating system.


```{r}
kgwr_residential_modelling <- kgwr_residential_modelling |>
  select(energie_waermequelle_heizung_primaer_gruppiert,
         gemeindename, 
         e_gebaeudekoordinate, 
         n_gebaeudekoordinate, 
         gebaeudeklasse_code, 
         baujahr_des_gebaeudes,
         gebaeudeflaeche,
         anzahl_geschosse)
  
```



## Initialize the h2o cluster

We can now initialize the h2o cluster (with 1GB memory, please do not change)...


```{r}
# Initialize the H2O-3 cluster
h2o.init(max_mem_size = "1g")
```


## Create train and test set

...and transform the data into a h2o dataframe. We will use 80% of the observations for training and keep 20% for the test dataset.


```{r}


# convert to H2O frame
kgwr_residential_modelling.h2o <- as.h2o(kgwr_residential_modelling)

# Split your data into 3 and save into variable "splits"
splits <- h2o.splitFrame(kgwr_residential_modelling.h2o, c(0.8), seed = 42)

# Extract all 3 splits into train, valid and test
train <- splits[[1]]
test  <- splits[[2]]

# Check the dimensions of both sets
dim(train)
dim(test)
```



## Define target and predictor variables

Our target variable `y` is `energie_waermequelle_heizung_primaer_gruppiert`. Since we removed all the unnecessary variables in the previous step, all the remaining variables can be assigned to `x` (predictors).


```{r}

# target
y <- "energie_waermequelle_heizung_primaer_gruppiert"

# predictors (everything but the target)
x <- setdiff(colnames(kgwr_residential_modelling.h2o), y)

```



## Run AutoML

Finally, we can run AutoML with the `h2o.automl()` function. The `max_runtime_secs` argument is set to 60 seconds. But you can play around with it and see how it affects the leaderboard. The `max_models` argument specifies the number of individual (or "base") models.


```{r}
aml_energy_source <- h2o.automl(y = y,
                                x = x,
                                training_frame = train,
                                #max_models = 10
                                max_runtime_secs = 60)
```



## Leaderboard

Next, we will view the AutoML Leaderboard. Since we did not specify a `leaderboard_frame` in the `h2o.automl()` function for scoring and ranking the models, the AutoML leaderboard uses cross-validation metrics to rank the models.

A default performance metric for each machine learning task (binary classification, multiclass classification, regression) is specified internally and the leaderboard will be sorted by that metric. In the case of multiclass classification problems, the default ranking metric is the **mean per-class error**.


```{r}
# View the AutoML Leaderboard
lb <- h2o.get_leaderboard(aml_energy_source)
print(lb, n = nrow(lb))  # Print all rows instead of default (6 rows)
```


## Get performance on test data

With the `h2o.performance()` function, we can evaluate the performance of any trained model on the test set. If we want to check the performance of the best model, we can simply pass `aml_energy_source@leader` to the function:


```{r}
# Performance of the leader model on test set
perf_best_model <- h2o.performance(aml_energy_source@leader, test)
```


With `h2o.confusionMatrix()` , we can evaluate the performance of any trained model on the test set. The rows represent the actual values and the columns the predicted values:


```{r}
# Get confusion matrix of overall best model
h2o.confusionMatrix(perf_best_model)
```


It is also possible to retrieve any trained model from the leaderboard by the model ID with `h2o.getModel(model_id)` and then evaluate the performance of that specific model. If you want to retrieve the best model of a specific algorithm, you can you the `h2o.get_best_model` function


```{r}
# Get the best XGBoost model
best_xgb <- h2o.get_best_model(aml_energy_source, algorithm = "xgboost")

# Performance of the best XGBoost model
perf_best_xgb_model <- h2o.performance(best_xgb, test)
```



And again, you can have a look at the confusion matrix:


```{r}
# Get confusion matrix of best XGBoost model
h2o.confusionMatrix(perf_best_xgb_model)
```



## Bonus: Model explainabilty

`h2o` offers a variety of function for model explainability (see [documentation](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/explain.html)). For example, you can directly retrieve a variable importance plot via `h2o.varimp_plot(best_xgb)`.  

```{r}

h2o.varimp_plot(best_xgb)

```


There is also the high-level function `h2o.explain()` that will generate all the available explanations of a given model (or also for an AutoML object). 


```{r}
# Explain a model
explanations <- h2o.explain(best_xgb, test)
explanations

```

